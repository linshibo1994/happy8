# å¿«ä¹8é¢„æµ‹ç³»ç»Ÿè®¾è®¡æ–‡æ¡£

## 1. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 1.1 æ€»ä½“æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·ç•Œé¢å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Streamlit Webç•Œé¢  â”‚    å‘½ä»¤è¡Œç•Œé¢      â”‚    REST APIæ¥å£    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¸šåŠ¡é€»è¾‘å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Happy8Analyzer    â”‚  PredictionEngine â”‚ ComparisonEngine  â”‚
â”‚   (æ ¸å¿ƒåˆ†æå™¨)       â”‚   (é¢„æµ‹å¼•æ“)       â”‚   (å¯¹æ¯”å¼•æ“)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç®—æ³•å®ç°å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   åŸºç¡€ç»Ÿè®¡ç®—æ³•       â”‚   æœºå™¨å­¦ä¹ ç®—æ³•     â”‚   æ·±åº¦å­¦ä¹ ç®—æ³•     â”‚
â”‚   - é¢‘ç‡åˆ†æ        â”‚   - é©¬å°”å¯å¤«é“¾     â”‚   - LSTMç½‘ç»œ      â”‚
â”‚   - å†·çƒ­å·åˆ†æ      â”‚   - èšç±»åˆ†æ       â”‚   - Transformer   â”‚
â”‚   - é—æ¼åˆ†æ        â”‚   - é›†æˆå­¦ä¹        â”‚   - å›¾ç¥ç»ç½‘ç»œ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®å¤„ç†å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   æ•°æ®çˆ¬å–æ¨¡å—       â”‚   æ•°æ®éªŒè¯æ¨¡å—     â”‚   ç‰¹å¾å·¥ç¨‹æ¨¡å—     â”‚
â”‚   - å®˜ç½‘çˆ¬è™«        â”‚   - å®Œæ•´æ€§æ£€æŸ¥     â”‚   - ç»Ÿè®¡ç‰¹å¾       â”‚
â”‚   - ç¬¬ä¸‰æ–¹æ•°æ®æº    â”‚   - æ ¼å¼éªŒè¯       â”‚   - åˆ†å¸ƒç‰¹å¾       â”‚
â”‚   - å®æ—¶æ›´æ–°        â”‚   - å¼‚å¸¸æ£€æµ‹       â”‚   - åºåˆ—ç‰¹å¾       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒæ¨¡å—å…³ç³»å›¾
```
Happy8Analyzer
    â”œâ”€â”€ DataManager (æ•°æ®ç®¡ç†å™¨)
    â”‚   â”œâ”€â”€ DataCrawler (æ•°æ®çˆ¬è™«)
    â”‚   â”œâ”€â”€ DataValidator (æ•°æ®éªŒè¯å™¨)
    â”‚   â””â”€â”€ DataStorage (æ•°æ®å­˜å‚¨)
    â”‚
    â”œâ”€â”€ PredictionEngine (é¢„æµ‹å¼•æ“)
    â”‚   â”œâ”€â”€ FrequencyPredictor (é¢‘ç‡é¢„æµ‹å™¨)
    â”‚   â”œâ”€â”€ MarkovPredictor (é©¬å°”å¯å¤«é¢„æµ‹å™¨)
    â”‚   â”œâ”€â”€ LSTMPredictor (LSTMé¢„æµ‹å™¨)
    â”‚   â””â”€â”€ EnsemblePredictor (é›†æˆé¢„æµ‹å™¨)
    â”‚
    â”œâ”€â”€ ComparisonEngine (å¯¹æ¯”å¼•æ“)
    â”‚   â”œâ”€â”€ ResultComparator (ç»“æœå¯¹æ¯”å™¨)
    â”‚   â”œâ”€â”€ HitRateCalculator (å‘½ä¸­ç‡è®¡ç®—å™¨)
    â”‚   â””â”€â”€ ReportGenerator (æŠ¥å‘Šç”Ÿæˆå™¨)
    â”‚
    â””â”€â”€ FeatureEngine (ç‰¹å¾å¼•æ“)
        â”œâ”€â”€ StatisticalFeatures (ç»Ÿè®¡ç‰¹å¾)
        â”œâ”€â”€ DistributionFeatures (åˆ†å¸ƒç‰¹å¾)
        â””â”€â”€ SequenceFeatures (åºåˆ—ç‰¹å¾)
```

## 2. æ•°æ®æ¨¡å‹è®¾è®¡

### 2.1 æ ¸å¿ƒæ•°æ®ç»“æ„

#### 2.1.1 å¼€å¥–æ•°æ®æ¨¡å‹
```python
@dataclass
class Happy8Result:
    """å¿«ä¹8å¼€å¥–ç»“æœæ•°æ®æ¨¡å‹"""
    issue: str                    # æœŸå· (å¦‚: "20250813001")
    date: str                     # å¼€å¥–æ—¥æœŸ (å¦‚: "2025-08-13")
    time: str                     # å¼€å¥–æ—¶é—´ (å¦‚: "09:05:00")
    numbers: List[int]            # å¼€å¥–å·ç  (20ä¸ªæ•°å­—)
    
    # è¡ç”Ÿå±æ€§
    @property
    def number_sum(self) -> int:
        """å·ç æ€»å’Œ"""
        return sum(self.numbers)
    
    @property
    def number_avg(self) -> float:
        """å·ç å¹³å‡å€¼"""
        return self.number_sum / 20
    
    @property
    def number_range(self) -> int:
        """å·ç è·¨åº¦"""
        return max(self.numbers) - min(self.numbers)
    
    @property
    def odd_count(self) -> int:
        """å¥‡æ•°ä¸ªæ•°"""
        return sum(1 for n in self.numbers if n % 2 == 1)
    
    @property
    def big_count(self) -> int:
        """å¤§å·ä¸ªæ•° (41-80)"""
        return sum(1 for n in self.numbers if n >= 41)
    
    @property
    def zone_distribution(self) -> List[int]:
        """åŒºåŸŸåˆ†å¸ƒ (1-80åˆ†ä¸º8ä¸ªåŒºåŸŸ)"""
        zones = [0] * 8
        for num in self.numbers:
            zone_idx = (num - 1) // 10
            zones[zone_idx] += 1
        return zones
```

#### 2.1.2 é¢„æµ‹ç»“æœæ¨¡å‹
```python
@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœæ•°æ®æ¨¡å‹"""
    target_issue: str             # ç›®æ ‡æœŸå·
    analysis_periods: int         # åˆ†ææœŸæ•°
    method: str                   # é¢„æµ‹æ–¹æ³•
    predicted_numbers: List[int]  # é¢„æµ‹å·ç 
    confidence_scores: List[float] # ç½®ä¿¡åº¦åˆ†æ•°
    generation_time: datetime     # ç”Ÿæˆæ—¶é—´
    execution_time: float         # æ‰§è¡Œè€—æ—¶
    
    # é¢„æµ‹å‚æ•°
    parameters: Dict[str, Any]    # ç®—æ³•å‚æ•°
    
    @property
    def top_numbers(self) -> List[int]:
        """æŒ‰ç½®ä¿¡åº¦æ’åºçš„å‰20ä¸ªå·ç """
        paired = list(zip(self.predicted_numbers, self.confidence_scores))
        sorted_pairs = sorted(paired, key=lambda x: x[1], reverse=True)
        return [num for num, _ in sorted_pairs[:20]]
```

#### 2.1.3 å¯¹æ¯”ç»“æœæ¨¡å‹
```python
@dataclass
class ComparisonResult:
    """å¯¹æ¯”ç»“æœæ•°æ®æ¨¡å‹"""
    target_issue: str             # ç›®æ ‡æœŸå·
    predicted_numbers: List[int]  # é¢„æµ‹å·ç 
    actual_numbers: List[int]     # å®é™…å¼€å¥–å·ç 
    hit_numbers: List[int]        # å‘½ä¸­å·ç 
    miss_numbers: List[int]       # æœªå‘½ä¸­å·ç 
    
    # ç»Ÿè®¡ä¿¡æ¯
    hit_count: int               # å‘½ä¸­æ•°é‡
    total_predicted: int         # é¢„æµ‹æ€»æ•°
    hit_rate: float             # å‘½ä¸­ç‡
    
    # åˆ†æä¿¡æ¯
    hit_distribution: Dict[str, int]  # å‘½ä¸­åˆ†å¸ƒåˆ†æ
    comparison_time: datetime    # å¯¹æ¯”æ—¶é—´
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        return f"""
å¯¹æ¯”ç»“æœæŠ¥å‘Š
============
ç›®æ ‡æœŸå·: {self.target_issue}
é¢„æµ‹æ•°é‡: {self.total_predicted}
å‘½ä¸­æ•°é‡: {self.hit_count}
å‘½ä¸­ç‡: {self.hit_rate:.2%}

å‘½ä¸­å·ç : {sorted(self.hit_numbers)}
æœªå‘½ä¸­å·ç : {sorted(self.miss_numbers)}
        """
```

### 2.2 æ•°æ®åº“è®¾è®¡

#### 2.2.1 CSVæ–‡ä»¶ç»“æ„
```csv
# happy8_results.csv - å¼€å¥–ç»“æœæ•°æ®
issue,date,time,num1,num2,num3,num4,num5,num6,num7,num8,num9,num10,num11,num12,num13,num14,num15,num16,num17,num18,num19,num20
20250813001,2025-08-13,09:05:00,3,7,12,15,23,28,31,35,42,47,51,56,62,67,71,74,76,78,79,80

# prediction_history.csv - é¢„æµ‹å†å²è®°å½•
timestamp,target_issue,method,analysis_periods,predicted_count,hit_count,hit_rate,execution_time
2025-08-13 10:30:00,20250813001,frequency,300,30,13,0.433,8.5

# performance_metrics.csv - æ€§èƒ½æŒ‡æ ‡è®°å½•
method,avg_hit_rate,total_predictions,avg_execution_time,last_updated
frequency,0.425,156,3.2,2025-08-13 10:30:00
markov,0.438,89,5.8,2025-08-13 10:25:00
```

## 3. æ ¸å¿ƒç±»è®¾è®¡

### 3.1 Happy8Analyzer æ ¸å¿ƒåˆ†æå™¨

```python
class Happy8Analyzer:
    """å¿«ä¹8åˆ†æå™¨æ ¸å¿ƒç±»"""
    
    def __init__(self, data_dir: str = "data"):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.data_dir = Path(data_dir)
        self.data_manager = DataManager(data_dir)
        self.prediction_engine = PredictionEngine(self)
        self.comparison_engine = ComparisonEngine(self)
        self.feature_engine = FeatureEngine(self)
        
        # æ•°æ®ç¼“å­˜
        self.historical_data: Optional[pd.DataFrame] = None
        self.feature_cache: Dict[str, Any] = {}
        
        # æ€§èƒ½ç›‘æ§
        self.performance_monitor = PerformanceMonitor()
    
    def load_data(self, periods: Optional[int] = None) -> pd.DataFrame:
        """åŠ è½½å†å²æ•°æ®"""
        if self.historical_data is None:
            self.historical_data = self.data_manager.load_historical_data()
        
        if periods:
            return self.historical_data.tail(periods)
        return self.historical_data
    
    def predict(self, 
                target_issue: str,
                periods: int = 300,
                count: int = 30,
                method: str = 'frequency',
                **kwargs) -> PredictionResult:
        """æ‰§è¡Œé¢„æµ‹"""
        
        # åŠ è½½æ•°æ®
        data = self.load_data(periods)
        
        # æ‰§è¡Œé¢„æµ‹
        start_time = time.time()
        result = self.prediction_engine.predict(
            data=data,
            target_issue=target_issue,
            count=count,
            method=method,
            **kwargs
        )
        execution_time = time.time() - start_time
        
        # è®°å½•æ€§èƒ½
        self.performance_monitor.record_prediction(method, execution_time)
        
        return result
    
    def compare_results(self, 
                       target_issue: str,
                       predicted_numbers: List[int]) -> ComparisonResult:
        """å¯¹æ¯”é¢„æµ‹ç»“æœ"""
        
        # è·å–å¼€å¥–ç»“æœ
        actual_result = self.data_manager.get_issue_result(target_issue)
        if not actual_result:
            raise ValueError(f"æœªæ‰¾åˆ°æœŸå· {target_issue} çš„å¼€å¥–ç»“æœ")
        
        # æ‰§è¡Œå¯¹æ¯”
        return self.comparison_engine.compare(
            target_issue=target_issue,
            predicted_numbers=predicted_numbers,
            actual_numbers=actual_result.numbers
        )
    
    def analyze_and_predict(self,
                           target_issue: str,
                           periods: int = 300,
                           count: int = 30,
                           method: str = 'frequency',
                           **kwargs) -> Tuple[PredictionResult, ComparisonResult]:
        """åˆ†æé¢„æµ‹å¹¶å¯¹æ¯”ç»“æœ"""
        
        # æ‰§è¡Œé¢„æµ‹
        prediction_result = self.predict(
            target_issue=target_issue,
            periods=periods,
            count=count,
            method=method,
            **kwargs
        )
        
        # å¯¹æ¯”ç»“æœ
        comparison_result = self.compare_results(
            target_issue=target_issue,
            predicted_numbers=prediction_result.predicted_numbers
        )
        
        return prediction_result, comparison_result
```

### 3.2 DataManager æ•°æ®ç®¡ç†å™¨

```python
class DataManager:
    """æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.data_file = self.data_dir / "happy8_results.csv"
        self.crawler = Happy8Crawler()
        self.validator = DataValidator()
    
    def load_historical_data(self) -> pd.DataFrame:
        """åŠ è½½å†å²æ•°æ®"""
        if not self.data_file.exists():
            self.crawl_initial_data()
        
        data = pd.read_csv(self.data_file)
        
        # æ•°æ®é¢„å¤„ç†
        data = self._preprocess_data(data)
        
        # æ•°æ®éªŒè¯
        self.validator.validate(data)
        
        return data
    
    def crawl_initial_data(self, count: int = 1000):
        """çˆ¬å–åˆå§‹æ•°æ®"""
        print(f"æ­£åœ¨çˆ¬å–æœ€è¿‘ {count} æœŸæ•°æ®...")
        
        results = self.crawler.crawl_recent_data(count)
        
        # ä¿å­˜æ•°æ®
        self._save_data(results)
        
        print(f"æˆåŠŸçˆ¬å– {len(results)} æœŸæ•°æ®")
    
    def update_latest_data(self):
        """æ›´æ–°æœ€æ–°æ•°æ®"""
        # è·å–æœ€æ–°æœŸå·
        latest_issue = self._get_latest_local_issue()
        
        # çˆ¬å–æ–°æ•°æ®
        new_results = self.crawler.crawl_since_issue(latest_issue)
        
        if new_results:
            self._append_data(new_results)
            print(f"æ›´æ–°äº† {len(new_results)} æœŸæ–°æ•°æ®")
        else:
            print("æ²¡æœ‰æ–°æ•°æ®éœ€è¦æ›´æ–°")
    
    def get_issue_result(self, issue: str) -> Optional[Happy8Result]:
        """è·å–æŒ‡å®šæœŸå·çš„å¼€å¥–ç»“æœ"""
        data = self.load_historical_data()
        
        # æŸ¥æ‰¾æŒ‡å®šæœŸå·
        issue_data = data[data['issue'] == issue]
        
        if issue_data.empty:
            # å°è¯•ä»ç½‘ç»œè·å–
            result = self.crawler.crawl_single_issue(issue)
            if result:
                self._append_data([result])
                return result
            return None
        
        # è½¬æ¢ä¸ºHappy8Resultå¯¹è±¡
        row = issue_data.iloc[0]
        return Happy8Result(
            issue=row['issue'],
            date=row['date'],
            time=row['time'],
            numbers=[row[f'num{i}'] for i in range(1, 21)]
        )
    
    def _preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®é¢„å¤„ç†"""
        # ç¡®ä¿æœŸå·æ’åº
        data = data.sort_values('issue')
        
        # æ·»åŠ è¡ç”Ÿåˆ—
        number_cols = [f'num{i}' for i in range(1, 21)]
        data['sum'] = data[number_cols].sum(axis=1)
        data['avg'] = data['sum'] / 20
        data['range'] = data[number_cols].max(axis=1) - data[number_cols].min(axis=1)
        
        return data
```

### 3.3 PredictionEngine é¢„æµ‹å¼•æ“

```python
class PredictionEngine:
    """é¢„æµ‹å¼•æ“"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.predictors = {
            'frequency': FrequencyPredictor(analyzer),
            'hot_cold': HotColdPredictor(analyzer),
            'missing': MissingPredictor(analyzer),
            'markov': MarkovPredictor(analyzer),
            'lstm': LSTMPredictor(analyzer),
            'ensemble': EnsemblePredictor(analyzer)
        }
    
    def predict(self,
                data: pd.DataFrame,
                target_issue: str,
                count: int,
                method: str,
                **kwargs) -> PredictionResult:
        """æ‰§è¡Œé¢„æµ‹"""
        
        if method not in self.predictors:
            raise ValueError(f"ä¸æ”¯æŒçš„é¢„æµ‹æ–¹æ³•: {method}")
        
        predictor = self.predictors[method]
        
        # æ‰§è¡Œé¢„æµ‹
        predicted_numbers, confidence_scores = predictor.predict(
            data=data,
            count=count,
            **kwargs
        )
        
        return PredictionResult(
            target_issue=target_issue,
            analysis_periods=len(data),
            method=method,
            predicted_numbers=predicted_numbers,
            confidence_scores=confidence_scores,
            generation_time=datetime.now(),
            execution_time=0,  # å°†åœ¨ä¸Šå±‚è®¾ç½®
            parameters=kwargs
        )
    
    def get_available_methods(self) -> List[str]:
        """è·å–å¯ç”¨çš„é¢„æµ‹æ–¹æ³•"""
        return list(self.predictors.keys())
```

### 3.4 å…·ä½“é¢„æµ‹å™¨å®ç°

#### 3.4.1 é¢‘ç‡åˆ†æé¢„æµ‹å™¨
```python
class FrequencyPredictor:
    """é¢‘ç‡åˆ†æé¢„æµ‹å™¨"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
    
    def predict(self, data: pd.DataFrame, count: int, **kwargs) -> Tuple[List[int], List[float]]:
        """åŸºäºé¢‘ç‡åˆ†æçš„é¢„æµ‹"""
        
        # ç»Ÿè®¡æ¯ä¸ªå·ç çš„å‡ºç°é¢‘ç‡
        frequency_stats = self._calculate_frequency(data)
        
        # æŒ‰é¢‘ç‡æ’åº
        sorted_numbers = sorted(frequency_stats.items(), key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©å‰countä¸ªå·ç 
        predicted_numbers = [num for num, freq in sorted_numbers[:count]]
        confidence_scores = [freq for num, freq in sorted_numbers[:count]]
        
        # å½’ä¸€åŒ–ç½®ä¿¡åº¦
        max_confidence = max(confidence_scores) if confidence_scores else 1
        confidence_scores = [score / max_confidence for score in confidence_scores]
        
        return predicted_numbers, confidence_scores
    
    def _calculate_frequency(self, data: pd.DataFrame) -> Dict[int, float]:
        """è®¡ç®—å·ç é¢‘ç‡"""
        frequency = {}
        
        # ç»Ÿè®¡æ¯ä¸ªå·ç å‡ºç°æ¬¡æ•°
        for i in range(1, 81):
            count = 0
            for _, row in data.iterrows():
                numbers = [row[f'num{j}'] for j in range(1, 21)]
                if i in numbers:
                    count += 1
            frequency[i] = count / len(data)
        
        return frequency
```

#### 3.4.2 é©¬å°”å¯å¤«é“¾é¢„æµ‹å™¨
```python
class MarkovPredictor:
    """é©¬å°”å¯å¤«é“¾é¢„æµ‹å™¨"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
    
    def predict(self, data: pd.DataFrame, count: int, order: int = 1, **kwargs) -> Tuple[List[int], List[float]]:
        """åŸºäºé©¬å°”å¯å¤«é“¾çš„é¢„æµ‹"""
        
        # æ„å»ºè½¬ç§»çŸ©é˜µ
        transition_matrix = self._build_transition_matrix(data, order)
        
        # è·å–æœ€è¿‘çŠ¶æ€
        recent_states = self._get_recent_states(data, order)
        
        # é¢„æµ‹ä¸‹ä¸€çŠ¶æ€
        predicted_probs = self._predict_next_state(transition_matrix, recent_states)
        
        # é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„å·ç 
        sorted_probs = sorted(predicted_probs.items(), key=lambda x: x[1], reverse=True)
        
        predicted_numbers = [num for num, prob in sorted_probs[:count]]
        confidence_scores = [prob for num, prob in sorted_probs[:count]]
        
        return predicted_numbers, confidence_scores
    
    def _build_transition_matrix(self, data: pd.DataFrame, order: int) -> np.ndarray:
        """æ„å»ºçŠ¶æ€è½¬ç§»çŸ©é˜µ"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºåŒºåŸŸçŠ¶æ€è½¬ç§»
        matrix = np.zeros((256, 256))  # 8ä¸ªåŒºåŸŸï¼Œæ¯ä¸ª0-4ä¸ªå·ç 
        
        for i in range(order, len(data)):
            prev_state = self._encode_state(data.iloc[i-order:i])
            curr_state = self._encode_state(data.iloc[i:i+1])
            matrix[prev_state][curr_state] += 1
        
        # å½’ä¸€åŒ–
        for i in range(256):
            row_sum = np.sum(matrix[i])
            if row_sum > 0:
                matrix[i] /= row_sum
        
        return matrix
    
    def _encode_state(self, data: pd.DataFrame) -> int:
        """ç¼–ç çŠ¶æ€"""
        # åŸºäºåŒºåŸŸåˆ†å¸ƒç¼–ç çŠ¶æ€
        zone_counts = [0] * 8
        
        for _, row in data.iterrows():
            numbers = [row[f'num{i}'] for i in range(1, 21)]
            for num in numbers:
                zone_idx = (num - 1) // 10
                zone_counts[zone_idx] += 1
        
        # å°†åŒºåŸŸè®¡æ•°ç¼–ç ä¸ºçŠ¶æ€
        state = 0
        for i, count in enumerate(zone_counts):
            state += min(count, 4) * (5 ** i)
        
        return state % 256
```

## 4. ç®—æ³•è®¾è®¡

### 4.1 å¿«ä¹8ç‰¹è‰²ç®—æ³•

#### 4.1.1 åŒºåŸŸåˆ†æç®—æ³•
```python
class ZoneAnalyzer:
    """åŒºåŸŸåˆ†æå™¨"""
    
    @staticmethod
    def analyze_zone_distribution(data: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æåŒºåŸŸåˆ†å¸ƒ"""
        zone_stats = {f'zone_{i+1}': [] for i in range(8)}
        
        for _, row in data.iterrows():
            numbers = [row[f'num{i}'] for i in range(1, 21)]
            zone_counts = [0] * 8
            
            for num in numbers:
                zone_idx = (num - 1) // 10
                zone_counts[zone_idx] += 1
            
            for i, count in enumerate(zone_counts):
                zone_stats[f'zone_{i+1}'].append(count)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        result = {}
        for zone, counts in zone_stats.items():
            result[zone] = {
                'mean': np.mean(counts),
                'std': np.std(counts),
                'min': min(counts),
                'max': max(counts),
                'distribution': np.bincount(counts, minlength=6).tolist()
            }
        
        return result
    
    @staticmethod
    def predict_zone_distribution(zone_stats: Dict[str, Any]) -> List[int]:
        """é¢„æµ‹åŒºåŸŸåˆ†å¸ƒ"""
        predicted_zones = []
        
        for zone, stats in zone_stats.items():
            # åŸºäºå†å²åˆ†å¸ƒé¢„æµ‹
            distribution = stats['distribution']
            most_likely = np.argmax(distribution)
            predicted_zones.append(most_likely)
        
        return predicted_zones
```

#### 4.1.2 è¿å·åˆ†æç®—æ³•
```python
class ConsecutiveAnalyzer:
    """è¿å·åˆ†æå™¨"""
    
    @staticmethod
    def analyze_consecutive_patterns(data: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æè¿å·æ¨¡å¼"""
        consecutive_stats = {
            'max_consecutive': [],
            'consecutive_groups': [],
            'consecutive_positions': []
        }
        
        for _, row in data.iterrows():
            numbers = sorted([row[f'num{i}'] for i in range(1, 21)])
            
            # åˆ†æè¿å·
            consecutive_groups = []
            current_group = [numbers[0]]
            
            for i in range(1, len(numbers)):
                if numbers[i] == numbers[i-1] + 1:
                    current_group.append(numbers[i])
                else:
                    if len(current_group) >= 2:
                        consecutive_groups.append(current_group)
                    current_group = [numbers[i]]
            
            if len(current_group) >= 2:
                consecutive_groups.append(current_group)
            
            # ç»Ÿè®¡ä¿¡æ¯
            max_consecutive = max(len(group) for group in consecutive_groups) if consecutive_groups else 0
            consecutive_stats['max_consecutive'].append(max_consecutive)
            consecutive_stats['consecutive_groups'].append(len(consecutive_groups))
        
        return {
            'avg_max_consecutive': np.mean(consecutive_stats['max_consecutive']),
            'avg_consecutive_groups': np.mean(consecutive_stats['consecutive_groups']),
            'max_consecutive_distribution': np.bincount(consecutive_stats['max_consecutive']).tolist()
        }
```

### 4.2 æ·±åº¦å­¦ä¹ ç®—æ³•é€‚é…

#### 4.2.1 LSTMé¢„æµ‹å™¨
```python
class LSTMPredictor:
    """LSTMé¢„æµ‹å™¨"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.model = None
        self.scaler = StandardScaler()
    
    def predict(self, data: pd.DataFrame, count: int, **kwargs) -> Tuple[List[int], List[float]]:
        """LSTMé¢„æµ‹"""
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X, y = self._prepare_training_data(data)
        
        # è®­ç»ƒæ¨¡å‹
        if self.model is None:
            self.model = self._build_model(X.shape)
            self._train_model(X, y)
        
        # æ‰§è¡Œé¢„æµ‹
        predictions = self._predict_numbers(X, count)
        
        return predictions
    
    def _prepare_training_data(self, data: pd.DataFrame, sequence_length: int = 10):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # ç‰¹å¾å·¥ç¨‹
        features = []
        targets = []
        
        for i in range(len(data) - sequence_length):
            # è¾“å…¥åºåˆ—
            sequence_data = data.iloc[i:i+sequence_length]
            sequence_features = []
            
            for _, row in sequence_data.iterrows():
                # æå–ç‰¹å¾
                numbers = [row[f'num{j}'] for j in range(1, 21)]
                feature_vector = self._extract_features(numbers)
                sequence_features.append(feature_vector)
            
            features.append(sequence_features)
            
            # ç›®æ ‡ï¼šä¸‹ä¸€æœŸçš„å·ç 
            next_row = data.iloc[i + sequence_length]
            next_numbers = [next_row[f'num{j}'] for j in range(1, 21)]
            targets.append(self._encode_target(next_numbers))
        
        X = np.array(features)
        y = np.array(targets)
        
        return X, y
    
    def _extract_features(self, numbers: List[int]) -> List[float]:
        """æå–ç‰¹å¾å‘é‡"""
        features = []
        
        # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
        features.extend([
            sum(numbers) / 20,  # å¹³å‡å€¼
            (max(numbers) - min(numbers)) / 80,  # å½’ä¸€åŒ–è·¨åº¦
            sum(1 for n in numbers if n % 2 == 1) / 20,  # å¥‡æ•°æ¯”ä¾‹
            sum(1 for n in numbers if n >= 41) / 20,  # å¤§å·æ¯”ä¾‹
        ])
        
        # åŒºåŸŸåˆ†å¸ƒç‰¹å¾
        zone_counts = [0] * 8
        for num in numbers:
            zone_idx = (num - 1) // 10
            zone_counts[zone_idx] += 1
        
        features.extend([count / 20 for count in zone_counts])
        
        # å·ç åˆ†å¸ƒç‰¹å¾ (ç®€åŒ–ä¸º10ä¸ªåŒºé—´)
        interval_counts = [0] * 10
        for num in numbers:
            interval_idx = (num - 1) // 8
            interval_counts[interval_idx] += 1
        
        features.extend([count / 20 for count in interval_counts])
        
        return features
    
    def _build_model(self, input_shape):
        """æ„å»ºLSTMæ¨¡å‹"""
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(128, return_sequences=True, input_shape=input_shape[1:]),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.LSTM(64, return_sequences=False),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(80, activation='sigmoid')  # 80ä¸ªå·ç çš„æ¦‚ç‡
        ])
        
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
```

## 5. ç”¨æˆ·ç•Œé¢è®¾è®¡

### 5.1 Webç•Œé¢è®¾è®¡

#### 5.1.1 ä¸»é¡µé¢å¸ƒå±€
```python
def create_main_page():
    """åˆ›å»ºä¸»é¡µé¢"""
    st.set_page_config(
        page_title="å¿«ä¹8æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ",
        page_icon="ğŸ¯",
        layout="wide"
    )
    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ¯ å¿«ä¹8æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‹ åŠŸèƒ½å¯¼èˆª")
        page = st.selectbox("é€‰æ‹©åŠŸèƒ½", [
            "ğŸ  é¦–é¡µ",
            "ğŸ“Š æ•°æ®ç®¡ç†", 
            "ğŸ¯ æ™ºèƒ½é¢„æµ‹",
            "ğŸ“ˆ ç»“æœåˆ†æ",
            "ğŸ“‹ å†å²è®°å½•",
            "âš™ï¸ ç³»ç»Ÿè®¾ç½®"
        ])
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if page == "ğŸ  é¦–é¡µ":
        show_homepage()
    elif page == "ğŸ“Š æ•°æ®ç®¡ç†":
        show_data_management()
    elif page == "ğŸ¯ æ™ºèƒ½é¢„æµ‹":
        show_prediction_interface()
    elif page == "ğŸ“ˆ ç»“æœåˆ†æ":
        show_result_analysis()
    elif page == "ğŸ“‹ å†å²è®°å½•":
        show_history_records()
    elif page == "âš™ï¸ ç³»ç»Ÿè®¾ç½®":
        show_system_settings()

def show_prediction_interface():
    """é¢„æµ‹ç•Œé¢"""
    st.header("ğŸ¯ æ™ºèƒ½é¢„æµ‹")
    
    # é¢„æµ‹å‚æ•°é…ç½®
    col1, col2, col3 = st.columns(3)
    
    with col1:
        target_issue = st.text_input(
            "ç›®æ ‡æœŸå·", 
            value="20250813001",
            help="è¾“å…¥è¦é¢„æµ‹çš„æœŸå·"
        )
    
    with col2:
        analysis_periods = st.selectbox(
            "åˆ†ææœŸæ•°",
            [100, 200, 300, 500, 1000],
            index=2,
            help="ç”¨äºåˆ†æçš„å†å²æœŸæ•°"
        )
    
    with col3:
        predict_count = st.selectbox(
            "ç”Ÿæˆå·ç æ•°",
            [10, 20, 30, 50],
            index=2,
            help="ç”Ÿæˆçš„é¢„æµ‹å·ç æ•°é‡"
        )
    
    # é¢„æµ‹æ–¹æ³•é€‰æ‹©
    method = st.selectbox(
        "é¢„æµ‹æ–¹æ³•",
        ["frequency", "hot_cold", "missing", "markov", "lstm", "ensemble"],
        format_func=lambda x: {
            "frequency": "é¢‘ç‡åˆ†æ",
            "hot_cold": "å†·çƒ­å·åˆ†æ", 
            "missing": "é—æ¼åˆ†æ",
            "markov": "é©¬å°”å¯å¤«é“¾",
            "lstm": "LSTMç¥ç»ç½‘ç»œ",
            "ensemble": "é›†æˆå­¦ä¹ "
        }[x]
    )
    
    # é¢„æµ‹æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
        with st.spinner("æ­£åœ¨æ‰§è¡Œé¢„æµ‹..."):
            try:
                analyzer = Happy8Analyzer()
                prediction_result, comparison_result = analyzer.analyze_and_predict(
                    target_issue=target_issue,
                    periods=analysis_periods,
                    count=predict_count,
                    method=method
                )
                
                # æ˜¾ç¤ºç»“æœ
                display_prediction_results(prediction_result, comparison_result)
                
            except Exception as e:
                st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")

def display_prediction_results(prediction_result, comparison_result):
    """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
    st.success("é¢„æµ‹å®Œæˆ!")
    
    # é¢„æµ‹å‚æ•°å›æ˜¾
    st.subheader("ğŸ“‹ é¢„æµ‹å‚æ•°")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ç›®æ ‡æœŸå·", prediction_result.target_issue)
    col2.metric("åˆ†ææœŸæ•°", prediction_result.analysis_periods)
    col3.metric("é¢„æµ‹æ–¹æ³•", prediction_result.method)
    col4.metric("æ‰§è¡Œè€—æ—¶", f"{prediction_result.execution_time:.2f}ç§’")
    
    # é¢„æµ‹å·ç å±•ç¤º
    st.subheader("ğŸ¯ é¢„æµ‹å·ç ")
    predicted_numbers = prediction_result.predicted_numbers
    
    # åˆ›å»ºå·ç ç½‘æ ¼
    cols = st.columns(10)
    for i, num in enumerate(predicted_numbers):
        col_idx = i % 10
        if num in comparison_result.hit_numbers:
            cols[col_idx].markdown(f"<div style='background-color: #ff4444; color: white; padding: 5px; text-align: center; border-radius: 5px; margin: 2px;'><b>{num:02d}</b></div>", unsafe_allow_html=True)
        else:
            cols[col_idx].markdown(f"<div style='background-color: #f0f0f0; padding: 5px; text-align: center; border-radius: 5px; margin: 2px;'>{num:02d}</div>", unsafe_allow_html=True)
    
    # å¼€å¥–å·ç å±•ç¤º
    st.subheader("ğŸ² å¼€å¥–å·ç ")
    actual_numbers = comparison_result.actual_numbers
    
    cols = st.columns(10)
    for i, num in enumerate(actual_numbers[:10]):  # æ˜¾ç¤ºå‰10ä¸ª
        cols[i].markdown(f"<div style='background-color: #4CAF50; color: white; padding: 5px; text-align: center; border-radius: 5px; margin: 2px;'><b>{num:02d}</b></div>", unsafe_allow_html=True)
    
    cols = st.columns(10)
    for i, num in enumerate(actual_numbers[10:]):  # æ˜¾ç¤ºå10ä¸ª
        cols[i].markdown(f"<div style='background-color: #4CAF50; color: white; padding: 5px; text-align: center; border-radius: 5px; margin: 2px;'><b>{num:02d}</b></div>", unsafe_allow_html=True)
    
    # å‘½ä¸­ç»Ÿè®¡
    st.subheader("ğŸ“Š å‘½ä¸­ç»Ÿè®¡")
    col1, col2, col3 = st.columns(3)
    col1.metric("å‘½ä¸­æ•°é‡", f"{comparison_result.hit_count}/{len(predicted_numbers)}")
    col2.metric("å‘½ä¸­ç‡", f"{comparison_result.hit_rate:.2%}")
    col3.metric("å‘½ä¸­å·ç ", ", ".join(map(str, sorted(comparison_result.hit_numbers))))
```

### 5.2 å‘½ä»¤è¡Œç•Œé¢è®¾è®¡

#### 5.2.1 CLIå‘½ä»¤ç»“æ„
```python
class Happy8CLI:
    """å¿«ä¹8å‘½ä»¤è¡Œç•Œé¢"""
    
    def __init__(self):
        self.analyzer = Happy8Analyzer()
        self.parser = self._create_parser()
    
    def _create_parser(self):
        """åˆ›å»ºå‘½ä»¤è¡Œè§£æå™¨"""
        parser = argparse.ArgumentParser(
            description="å¿«ä¹8æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s crawl --count 1000
  %(prog)s predict --target 20250813001 --periods 300 --count 30 --method frequency
  %(prog)s compare --target 20250813001 --periods 300 --count 30 --method ensemble
            """
        )
        
        subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
        
        # æ•°æ®ç®¡ç†å‘½ä»¤
        crawl_parser = subparsers.add_parser('crawl', help='çˆ¬å–å†å²æ•°æ®')
        crawl_parser.add_argument('--count', type=int, default=1000, help='çˆ¬å–æœŸæ•°')
        
        update_parser = subparsers.add_parser('update', help='æ›´æ–°æœ€æ–°æ•°æ®')
        
        validate_parser = subparsers.add_parser('validate', help='éªŒè¯æ•°æ®å®Œæ•´æ€§')
        
        # é¢„æµ‹å‘½ä»¤
        predict_parser = subparsers.add_parser('predict', help='æ‰§è¡Œé¢„æµ‹')
        predict_parser.add_argument('--target', required=True, help='ç›®æ ‡æœŸå·')
        predict_parser.add_argument('--periods', type=int, default=300, help='åˆ†ææœŸæ•°')
        predict_parser.add_argument('--count', type=int, default=30, help='ç”Ÿæˆå·ç æ•°')
        predict_parser.add_argument('--method', default='frequency', help='é¢„æµ‹æ–¹æ³•')
        predict_parser.add_argument('--explain', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹')
        
        # å¯¹æ¯”å‘½ä»¤
        compare_parser = subparsers.add_parser('compare', help='é¢„æµ‹å¹¶å¯¹æ¯”ç»“æœ')
        compare_parser.add_argument('--target', required=True, help='ç›®æ ‡æœŸå·')
        compare_parser.add_argument('--periods', type=int, default=300, help='åˆ†ææœŸæ•°')
        compare_parser.add_argument('--count', type=int, default=30, help='ç”Ÿæˆå·ç æ•°')
        compare_parser.add_argument('--method', default='frequency', help='é¢„æµ‹æ–¹æ³•')
        compare_parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
        
        return parser
    
    def run(self, args=None):
        """è¿è¡ŒCLI"""
        args = self.parser.parse_args(args)
        
        if args.command == 'crawl':
            self._handle_crawl(args)
        elif args.command == 'update':
            self._handle_update(args)
        elif args.command == 'validate':
            self._handle_validate(args)
        elif args.command == 'predict':
            self._handle_predict(args)
        elif args.command == 'compare':
            self._handle_compare(args)
        else:
            self.parser.print_help()
    
    def _handle_compare(self, args):
        """å¤„ç†å¯¹æ¯”å‘½ä»¤"""
        print("å¿«ä¹8æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ")
        print("=" * 50)
        print()
        
        print("é¢„æµ‹å‚æ•°:")
        print(f"- ç›®æ ‡æœŸå·: {args.target}")
        print(f"- åˆ†ææœŸæ•°: {args.periods}æœŸ")
        print(f"- ç”Ÿæˆæ•°é‡: {args.count}ä¸ªå·ç ")
        print(f"- é¢„æµ‹æ–¹æ³•: {args.method}")
        print()
        
        try:
            # æ‰§è¡Œé¢„æµ‹å’Œå¯¹æ¯”
            print("æ­£åœ¨åŠ è½½æ•°æ®... ", end="")
            prediction_result, comparison_result = self.analyzer.analyze_and_predict(
                target_issue=args.target,
                periods=args.periods,
                count=args.count,
                method=args.method
            )
            print("âœ“")
            
            # æ˜¾ç¤ºç»“æœ
            self._display_cli_results(prediction_result, comparison_result)
            
            # ä¿å­˜ç»“æœ
            if args.output:
                self._save_results(prediction_result, comparison_result, args.output)
                print(f"\nç»“æœå·²ä¿å­˜åˆ°: {args.output}")
            
        except Exception as e:
            print(f"âœ—\né”™è¯¯: {str(e)}")
    
    def _display_cli_results(self, prediction_result, comparison_result):
        """æ˜¾ç¤ºCLIç»“æœ"""
        print("\né¢„æµ‹ç»“æœ:")
        print("=" * 50)
        
        # é¢„æµ‹å·ç 
        predicted_numbers = prediction_result.predicted_numbers
        print(f"é¢„æµ‹å·ç  ({len(predicted_numbers)}ä¸ª):")
        
        # æŒ‰è¡Œæ˜¾ç¤ºï¼Œæ¯è¡Œ10ä¸ª
        for i in range(0, len(predicted_numbers), 10):
            line_numbers = predicted_numbers[i:i+10]
            formatted_numbers = []
            
            for num in line_numbers:
                if num in comparison_result.hit_numbers:
                    formatted_numbers.append(f"\033[91m[{num:02d}]\033[0m")  # çº¢è‰²æ ‡è®°
                else:
                    formatted_numbers.append(f"{num:02d}")
            
            print(" ".join(formatted_numbers))
        
        print()
        
        # å¼€å¥–å·ç 
        actual_numbers = comparison_result.actual_numbers
        print(f"å¼€å¥–å·ç  ({len(actual_numbers)}ä¸ª):")
        
        for i in range(0, len(actual_numbers), 10):
            line_numbers = actual_numbers[i:i+10]
            formatted_numbers = [f"\033[92m[{num:02d}]\033[0m" for num in line_numbers]  # ç»¿è‰²
            print(" ".join(formatted_numbers))
        
        print()
        
        # å‘½ä¸­åˆ†æ
        print("å‘½ä¸­åˆ†æ:")
        print("=" * 50)
        hit_numbers_str = " ".join([f"\033[91m{num:02d}\033[0m" for num in sorted(comparison_result.hit_numbers)])
        print(f"å‘½ä¸­å·ç : {hit_numbers_str}")
        print(f"å‘½ä¸­æ•°é‡: {comparison_result.hit_count}/{len(predicted_numbers)}")
        print(f"å‘½ä¸­ç‡: {comparison_result.hit_rate:.2%}")
        
        # è¯¦ç»†åˆ†æ
        self._display_detailed_analysis(comparison_result)
        
        print(f"\né¢„æµ‹å®Œæˆ! ç”¨æ—¶: {prediction_result.execution_time:.2f}ç§’")
    
    def _display_detailed_analysis(self, comparison_result):
        """æ˜¾ç¤ºè¯¦ç»†åˆ†æ"""
        hit_numbers = comparison_result.hit_numbers
        
        # å¤§å°å·åˆ†æ
        small_hits = sum(1 for num in hit_numbers if num <= 40)
        big_hits = len(hit_numbers) - small_hits
        
        # å¥‡å¶åˆ†æ
        odd_hits = sum(1 for num in hit_numbers if num % 2 == 1)
        even_hits = len(hit_numbers) - odd_hits
        
        # åŒºåŸŸåˆ†æ
        zone_hits = [0] * 8
        for num in hit_numbers:
            zone_idx = (num - 1) // 10
            zone_hits[zone_idx] += 1
        
        print("\nè¯¦ç»†åˆ†æ:")
        print(f"- å°å·å‘½ä¸­: {small_hits}ä¸ª (1-40å·æ®µ)")
        print(f"- å¤§å·å‘½ä¸­: {big_hits}ä¸ª (41-80å·æ®µ)")
        print(f"- å¥‡æ•°å‘½ä¸­: {odd_hits}ä¸ª")
        print(f"- å¶æ•°å‘½ä¸­: {even_hits}ä¸ª")
        print(f"- å„åŒºåŸŸå‘½ä¸­åˆ†å¸ƒ: {zone_hits}")
```

## 6. æ€§èƒ½ä¼˜åŒ–è®¾è®¡

### 6.1 ç¼“å­˜ç­–ç•¥
```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.memory_cache = {}
        self.file_cache_dir = Path("cache")
        self.file_cache_dir.mkdir(exist_ok=True)
    
    def get_prediction_cache(self, cache_key: str) -> Optional[Any]:
        """è·å–é¢„æµ‹ç¼“å­˜"""
        # å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            return self.memory_cache[cache_key]
        
        # æ–‡ä»¶ç¼“å­˜
        cache_file = self.file_cache_dir / f"{cache_key}.pkl"
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                data = pickle.load(f)
                self.memory_cache[cache_key] = data
                return data
        
        return None
    
    def set_prediction_cache(self, cache_key: str, data: Any):
        """è®¾ç½®é¢„æµ‹ç¼“å­˜"""
        # å†…å­˜ç¼“å­˜
        self.memory_cache[cache_key] = data
        
        # æ–‡ä»¶ç¼“å­˜
        cache_file = self.file_cache_dir / f"{cache_key}.pkl"
        with open(cache_file, 'wb') as f:
            pickle.dump(data, f)
    
    def generate_cache_key(self, method: str, periods: int, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [method, str(periods)]
        for k, v in sorted(kwargs.items()):
            key_parts.append(f"{k}_{v}")
        return "_".join(key_parts)
```

### 6.2 å¹¶è¡Œå¤„ç†è®¾è®¡
```python
class ParallelProcessor:
    """å¹¶è¡Œå¤„ç†å™¨"""
    
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or cpu_count()
    
    def parallel_predict(self, 
                        analyzer: Happy8Analyzer,
                        methods: List[str],
                        **common_params) -> Dict[str, PredictionResult]:
        """å¹¶è¡Œæ‰§è¡Œå¤šç§é¢„æµ‹æ–¹æ³•"""
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            futures = {}
            for method in methods:
                future = executor.submit(
                    analyzer.predict,
                    method=method,
                    **common_params
                )
                futures[method] = future
            
            # æ”¶é›†ç»“æœ
            results = {}
            for method, future in futures.items():
                try:
                    results[method] = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                except Exception as e:
                    print(f"æ–¹æ³• {method} é¢„æµ‹å¤±è´¥: {str(e)}")
                    results[method] = None
            
            return results
```

## 7. æ•°æ®åº“è®¾è®¡

### 7.1 æ–‡ä»¶å­˜å‚¨ç»“æ„
```
data/
â”œâ”€â”€ happy8_results.csv          # ä¸»è¦å¼€å¥–æ•°æ®
â”œâ”€â”€ prediction_history.csv      # é¢„æµ‹å†å²è®°å½•
â”œâ”€â”€ performance_metrics.csv     # æ€§èƒ½æŒ‡æ ‡
â”œâ”€â”€ cache/                      # ç¼“å­˜ç›®å½•
â”‚   â”œâ”€â”€ frequency_cache.pkl
â”‚   â”œâ”€â”€ markov_cache.pkl
â”‚   â””â”€â”€ lstm_cache.pkl
â”œâ”€â”€ models/                     # æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ lstm_model.h5
â”‚   â”œâ”€â”€ transformer_model.h5
â”‚   â””â”€â”€ ensemble_model.pkl
â””â”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶
    â”œâ”€â”€ system.log
    â”œâ”€â”€ prediction.log
    â””â”€â”€ error.log
```

### 7.2 æ•°æ®è¡¨ç»“æ„è®¾è®¡
```sql
-- å¦‚æœä½¿ç”¨SQLiteæ•°æ®åº“çš„è¡¨ç»“æ„è®¾è®¡

-- å¼€å¥–ç»“æœè¡¨
CREATE TABLE happy8_results (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    issue TEXT UNIQUE NOT NULL,
    date TEXT NOT NULL,
    time TEXT NOT NULL,
    numbers TEXT NOT NULL,  -- JSONæ ¼å¼å­˜å‚¨20ä¸ªå·ç 
    sum_value INTEGER,
    avg_value REAL,
    range_value INTEGER,
    odd_count INTEGER,
    big_count INTEGER,
    zone_distribution TEXT,  -- JSONæ ¼å¼å­˜å‚¨åŒºåŸŸåˆ†å¸ƒ
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- é¢„æµ‹å†å²è¡¨
CREATE TABLE prediction_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    target_issue TEXT NOT NULL,
    method TEXT NOT NULL,
    analysis_periods INTEGER NOT NULL,
    predicted_numbers TEXT NOT NULL,  -- JSONæ ¼å¼
    confidence_scores TEXT,           -- JSONæ ¼å¼
    hit_numbers TEXT,                 -- JSONæ ¼å¼
    hit_count INTEGER,
    hit_rate REAL,
    execution_time REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ€§èƒ½æŒ‡æ ‡è¡¨
CREATE TABLE performance_metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    method TEXT NOT NULL,
    avg_hit_rate REAL,
    total_predictions INTEGER,
    avg_execution_time REAL,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## 8. æµ‹è¯•è®¾è®¡

### 8.1 å•å…ƒæµ‹è¯•è®¾è®¡
```python
import unittest
from unittest.mock import Mock, patch
import pandas as pd

class TestHappy8Analyzer(unittest.TestCase):
    """Happy8Analyzeræµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.analyzer = Happy8Analyzer("test_data")
        self.test_data = self._create_test_data()
    
    def test_frequency_prediction(self):
        """æµ‹è¯•é¢‘ç‡é¢„æµ‹"""
        result = self.analyzer.predict(
            target_issue="20250813001",
            periods=100,
            count=30,
            method="frequency"
        )
        
        self.assertIsNotNone(result)
        self.assertEqual(len(result.predicted_numbers), 30)
        self.assertTrue(all(1 <= num <= 80 for num in result.predicted_numbers))
    
    def test_markov_prediction(self):
        """æµ‹è¯•é©¬å°”å¯å¤«é¢„æµ‹"""
        result = self.analyzer.predict(
            target_issue="20250813001",
            periods=200,
            count=30,
            method="markov"
        )
        
        self.assertIsNotNone(result)
        self.assertEqual(len(result.predicted_numbers), 30)
    
    def test_result_comparison(self):
        """æµ‹è¯•ç»“æœå¯¹æ¯”"""
        predicted_numbers = list(range(1, 31))  # 1-30
        
        with patch.object(self.analyzer.data_manager, 'get_issue_result') as mock_get:
            mock_result = Happy8Result(
                issue="20250813001",
                date="2025-08-13",
                time="09:05:00",
                numbers=list(range(1, 21))  # 1-20
            )
            mock_get.return_value = mock_result
            
            comparison = self.analyzer.compare_results(
                target_issue="20250813001",
                predicted_numbers=predicted_numbers
            )
            
            self.assertEqual(comparison.hit_count, 20)  # 1-20éƒ½å‘½ä¸­
            self.assertEqual(comparison.hit_rate, 20/30)
    
    def _create_test_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        data = []
        for i in range(100):
            issue = f"2025081300{i+1:01d}"
            numbers = list(range(1 + i % 10, 21 + i % 10))  # æ¨¡æ‹Ÿæ•°æ®
            data.append({
                'issue': issue,
                'date': '2025-08-13',
                'time': '09:05:00',
                **{f'num{j}': numbers[j-1] for j in range(1, 21)}
            })
        
        return pd.DataFrame(data)

class TestPredictionEngine(unittest.TestCase):
    """é¢„æµ‹å¼•æ“æµ‹è¯•ç±»"""
    
    def setUp(self):
        self.analyzer = Mock()
        self.engine = PredictionEngine(self.analyzer)
    
    def test_available_methods(self):
        """æµ‹è¯•å¯ç”¨æ–¹æ³•"""
        methods = self.engine.get_available_methods()
        expected_methods = ['frequency', 'hot_cold', 'missing', 'markov', 'lstm', 'ensemble']
        
        for method in expected_methods:
            self.assertIn(method, methods)
```

### 8.2 é›†æˆæµ‹è¯•è®¾è®¡
```python
class TestIntegration(unittest.TestCase):
    """é›†æˆæµ‹è¯•ç±»"""
    
    def test_full_prediction_pipeline(self):
        """æµ‹è¯•å®Œæ•´é¢„æµ‹æµç¨‹"""
        analyzer = Happy8Analyzer("test_data")
        
        # 1. æ•°æ®åŠ è½½æµ‹è¯•
        data = analyzer.load_data(periods=100)
        self.assertGreater(len(data), 0)
        
        # 2. é¢„æµ‹æ‰§è¡Œæµ‹è¯•
        result = analyzer.predict(
            target_issue="20250813001",
            periods=100,
            count=30,
            method="frequency"
        )
        self.assertIsNotNone(result)
        
        # 3. ç»“æœå¯¹æ¯”æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿï¼‰
        with patch.object(analyzer.data_manager, 'get_issue_result') as mock_get:
            mock_result = Happy8Result(
                issue="20250813001",
                date="2025-08-13", 
                time="09:05:00",
                numbers=list(range(1, 21))
            )
            mock_get.return_value = mock_result
            
            comparison = analyzer.compare_results(
                target_issue="20250813001",
                predicted_numbers=result.predicted_numbers
            )
            
            self.assertIsNotNone(comparison)
            self.assertGreaterEqual(comparison.hit_rate, 0)
            self.assertLessEqual(comparison.hit_rate, 1)
```

## 9. éƒ¨ç½²è®¾è®¡

### 9.1 Dockerå®¹å™¨åŒ–
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºæ•°æ®ç›®å½•
RUN mkdir -p data cache logs

# æš´éœ²ç«¯å£
EXPOSE 8501

# å¯åŠ¨å‘½ä»¤
CMD ["streamlit", "run", "happy8_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  happy8-app:
    build: .
    ports:
      - "8501:8501"
    volumes:
      - ./data:/app/data
      - ./cache:/app/cache
      - ./logs:/app/logs
    environment:
      - PYTHONPATH=/app
      - TZ=Asia/Shanghai
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - happy8-app
    restart: unless-stopped
```

### 9.2 ç›‘æ§é…ç½®
```yaml
# monitoring/docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana

volumes:
  grafana-storage:
```

## 10. æ€»ç»“

æœ¬è®¾è®¡æ–‡æ¡£è¯¦ç»†æè¿°äº†å¿«ä¹8é¢„æµ‹ç³»ç»Ÿçš„æŠ€æœ¯æ¶æ„å’Œå®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

### 10.1 æ ¸å¿ƒç‰¹æ€§
- **å®Œæ•´çš„ç³»ç»Ÿæ¶æ„**: ä»æ•°æ®å±‚åˆ°ç•Œé¢å±‚çš„å®Œæ•´è®¾è®¡
- **å¤šç§é¢„æµ‹ç®—æ³•**: ç»Ÿè®¡å­¦ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç®—æ³•æ”¯æŒ
- **åŒé‡ç”¨æˆ·ç•Œé¢**: Webç•Œé¢å’Œå‘½ä»¤è¡Œç•Œé¢
- **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜ã€å¹¶è¡Œå¤„ç†ç­‰ä¼˜åŒ–ç­–ç•¥
- **å®¹å™¨åŒ–éƒ¨ç½²**: Dockerå®¹å™¨åŒ–å’Œç›‘æ§æ–¹æ¡ˆ

### 10.2 æŠ€æœ¯äº®ç‚¹
- **æ¨¡å—åŒ–è®¾è®¡**: å„åŠŸèƒ½æ¨¡å—ç‹¬ç«‹ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **ç¼“å­˜æœºåˆ¶**: æé«˜é¢„æµ‹æ€§èƒ½å’Œå“åº”é€Ÿåº¦
- **å¹¶è¡Œå¤„ç†**: æ”¯æŒå¤šç®—æ³•å¹¶è¡Œé¢„æµ‹
- **å®Œæ•´æµ‹è¯•**: å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•è¦†ç›–
- **ç›‘æ§è¿ç»´**: å®Œæ•´çš„ç›‘æ§å’Œæ—¥å¿—æ–¹æ¡ˆ

### 10.3 æ‰©å±•æ€§
- **ç®—æ³•æ‰©å±•**: æ”¯æŒæ–°ç®—æ³•çš„æ’ä»¶å¼é›†æˆ
- **æ¥å£æ‰©å±•**: REST APIæ”¯æŒç¬¬ä¸‰æ–¹é›†æˆ
- **éƒ¨ç½²æ‰©å±•**: æ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼å’Œäº‘å¹³å°

è¯¥è®¾è®¡æ–‡æ¡£ä¸ºå¿«ä¹8é¢„æµ‹ç³»ç»Ÿçš„å¼€å‘æä¾›äº†å®Œæ•´çš„æŠ€æœ¯æŒ‡å¯¼ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿæ»¡è¶³éœ€æ±‚æ–‡æ¡£ä¸­çš„æ‰€æœ‰åŠŸèƒ½å’Œæ€§èƒ½è¦æ±‚ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-16  
**æœ€åæ›´æ–°**: 2025-08-16  
**æ–‡æ¡£çŠ¶æ€**: å¾…è¯„å®¡
